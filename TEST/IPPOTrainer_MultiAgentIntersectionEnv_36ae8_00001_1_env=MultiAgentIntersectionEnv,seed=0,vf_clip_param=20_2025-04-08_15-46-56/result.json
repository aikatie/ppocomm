{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6123432371871813, "cur_kl_coeff": 0.19999999999999996, "cur_lr": 0.0003, "total_loss": 0.6226441524949456, "policy_loss": -0.0020438735812370267, "vf_loss": 0.6236055776204116, "vf_explained_var": -0.07993557819298336, "kl": 0.005412252913644937, "entropy": 2.8487159500803267, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 512.0, "num_grad_updates_lifetime": 350.5, "diff_num_grad_updates_vs_sampler_policy": 349.5}}, "num_env_steps_sampled": 2400, "num_env_steps_trained": 2400, "num_agent_steps_sampled": 71918, "num_agent_steps_trained": 71918}, "sampler_results": {"episode_reward_max": NaN, "episode_reward_min": NaN, "episode_reward_mean": NaN, "episode_len_mean": NaN, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [], "episode_lengths": []}, "sampler_perf": {}, "num_faulty_episodes": 0}, "episode_reward_max": NaN, "episode_reward_min": NaN, "episode_reward_mean": NaN, "episode_len_mean": NaN, "episodes_this_iter": 0, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [], "episode_lengths": []}, "sampler_perf": {}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 1, "num_agent_steps_sampled": 71918, "num_agent_steps_trained": 71918, "num_env_steps_sampled": 2400, "num_env_steps_trained": 2400, "num_env_steps_sampled_this_iter": 2400, "num_env_steps_trained_this_iter": 2400, "timesteps_total": 2400, "num_steps_trained_this_iter": 2400, "agent_timesteps_total": 71918, "timers": {"training_iteration_time_ms": 41235.736, "load_time_ms": 0.776, "load_throughput": 3094475.745, "learn_time_ms": 14781.249, "learn_throughput": 162.368, "synch_weights_time_ms": 9.4}, "counters": {"num_env_steps_sampled": 2400, "num_env_steps_trained": 2400, "num_agent_steps_sampled": 71918, "num_agent_steps_trained": 71918}, "done": false, "episodes_total": 0, "training_iteration": 1, "trial_id": "36ae8_00001", "experiment_id": "c46a3f14a6004638947d78395a6e617d", "date": "2025-04-08_15-50-30", "timestamp": 1744141830, "time_this_iter_s": 41.32829928398132, "time_total_s": 41.32829928398132, "pid": 143644, "hostname": "aero", "node_ip": "172.31.139.253", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 0.2, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiAgentIntersectionEnv", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "train_batch_size": 2000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "INFO", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 512, "num_sgd_iter": 5, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 20, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1, "old_value_loss": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.95, "input": "sampler", "multiagent": {"policies": {"default": "<ray.rllib.policy.policy.PolicySpec object at 0x7f28dc719310>"}, "policy_mapping_fn": "<function IPPOConfig.validate.<locals>.<lambda> at 0x7f28dc6e04d0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'copo.torch_copo.utils.callbacks.MultiAgentDrivingCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 41.32829928398132, "timesteps_since_restore": 0, "iterations_since_restore": 1, "warmup_time": 170.1945035457611, "perf": {"cpu_util_percent": 46.241818181818175, "ram_util_percent": 94.46545454545453}, "success": NaN, "crash": NaN, "out": NaN, "max_step": NaN, "length": NaN, "rc": NaN, "cost": NaN, "raw_episode_reward_mean": NaN}

Failure # 1 (occurred at 2025-04-08_15-55-50)
Traceback (most recent call last):
  File "/home/awsl/anaconda3/envs/copo/lib/python3.7/site-packages/ray/tune/execution/ray_trial_executor.py", line 1070, in get_next_executor_event
    future_result = ray.get(ready_future)
  File "/home/awsl/anaconda3/envs/copo/lib/python3.7/site-packages/ray/_private/client_mode_hook.py", line 105, in wrapper
    return func(*args, **kwargs)
  File "/home/awsl/anaconda3/envs/copo/lib/python3.7/site-packages/ray/_private/worker.py", line 2311, in get
    raise value
ray.exceptions.RayActorError: The actor died unexpectedly before finishing this task.
	class_name: IPPOTrainer
	actor_id: d1c047b8f56717c972b3a9aa01000000
	pid: 143644
	namespace: f73553da-32a6-40c8-a4f3-c63c130092ad
	ip: 172.31.139.253
The actor is dead because its worker process has died. Worker exit type: SYSTEM_ERROR Worker exit detail: Worker unexpectedly exits with a connection error code 2. End of file. There are some potential root causes. (1) The process is killed by SIGKILL by OOM killer due to high memory usage. (2) ray stop --force is called. (3) The worker is crashed unexpectedly due to SIGSEGV or other unexpected errors.

Failure # 2 (occurred at 2025-04-08_16-00-47)
[36mray::IPPOTrainer.train()[39m (pid=193466, ip=172.31.139.253, repr=IPPOTrainer)
  File "/home/awsl/anaconda3/envs/copo/lib/python3.7/site-packages/ray/tune/trainable/trainable.py", line 367, in train
    raise skipped from exception_cause(skipped)
  File "/home/awsl/anaconda3/envs/copo/lib/python3.7/site-packages/ray/tune/trainable/trainable.py", line 364, in train
    result = self.step()
  File "/home/awsl/anaconda3/envs/copo/lib/python3.7/site-packages/ray/rllib/algorithms/algorithm.py", line 749, in step
    results, train_iter_ctx = self._run_one_training_iteration()
  File "/home/awsl/anaconda3/envs/copo/lib/python3.7/site-packages/ray/rllib/algorithms/algorithm.py", line 2623, in _run_one_training_iteration
    results = self.training_step()
  File "/home/awsl/anaconda3/envs/copo/lib/python3.7/site-packages/ray/rllib/algorithms/ppo/ppo.py", line 331, in training_step
    train_results = multi_gpu_train_one_step(self, train_batch)
  File "/home/awsl/anaconda3/envs/copo/lib/python3.7/site-packages/ray/rllib/execution/train_ops.py", line 140, in multi_gpu_train_one_step
    policy_id
  File "/home/awsl/anaconda3/envs/copo/lib/python3.7/site-packages/ray/rllib/utils/threading.py", line 24, in wrapper
    return func(self, *a, **k)
  File "/home/awsl/anaconda3/envs/copo/lib/python3.7/site-packages/ray/rllib/policy/policy_map.py", line 163, in __getitem__
    raise KeyError(f"PolicyID '{item}' not found in this PolicyMap!")
KeyError: "PolicyID 'default_policy' not found in this PolicyMap!"
